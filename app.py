# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FGwGozFLIMFn0uMv__61jiMiw0bTO_Wt

#HR Resource Query Chatbot

###Objective
Build an intelligent HR assistant chatbot that can answer resource allocation queries using
natural language processing and retrieval techniques.

###Problem Statement
Create an AI-powered chatbot that helps HR teams find employees by answering queries like:
* "Find Python developers with 3+ years experience"
* "Who has worked on healthcare projects?"
* "Suggest people for a React Native project"
* "Find developers who know both AWS and Docker"

### Core Requirements

**1. Data Layer**
"""

import json

data = {
  "employees": [
    {
      "id": 1,
      "name": "Alice Johnson",
      "skills": ["Python", "AWS", "Docker"],
      "experience_years": 5,
      "projects": ["E-commerce Platform", "Healthcare Dashboard"],
      "availability": "available"
    },
    {
      "id": 2,
      "name": "Bob Lee",
      "skills": ["React", "Node.js", "MongoDB"],
      "experience_years": 4,
      "projects": ["Social Media App", "Chatbot System"],
      "availability": "available"
    },
    {
      "id": 3,
      "name": "Clara Mendes",
      "skills": ["Machine Learning", "TensorFlow", "PyTorch"],
      "experience_years": 6,
      "projects": ["Medical Diagnosis Platform", "AI Stock Predictor"],
      "availability": "unavailable"
    },
    {
      "id": 4,
      "name": "David Kim",
      "skills": ["Java", "Spring Boot", "MySQL"],
      "experience_years": 3,
      "projects": ["Banking API", "HR Management System"],
      "availability": "available"
    },
    {
      "id": 5,
      "name": "Eva Shah",
      "skills": ["Python", "NLP", "Spacy"],
      "experience_years": 5,
      "projects": ["Resume Parser", "Sentiment Analyzer"],
      "availability": "available"
    },
    {
      "id": 6,
      "name": "Farhan Malik",
      "skills": ["React Native", "Firebase", "UI/UX"],
      "experience_years": 2,
      "projects": ["Fitness Tracker App", "E-learning App"],
      "availability": "unavailable"
    },
    {
      "id": 7,
      "name": "Grace Lee",
      "skills": ["AWS", "Kubernetes", "DevOps"],
      "experience_years": 7,
      "projects": ["Cloud Migration", "CI/CD Pipeline"],
      "availability": "available"
    },
    {
      "id": 8,
      "name": "Henry Wu",
      "skills": ["Docker", "Terraform", "GCP"],
      "experience_years": 5,
      "projects": ["Infrastructure Automation", "Healthcare Cloud"],
      "availability": "unavailable"
    },
    {
      "id": 9,
      "name": "Isabella Gomes",
      "skills": ["SQL", "Power BI", "ETL"],
      "experience_years": 4,
      "projects": ["Retail Analytics", "Financial Dashboard"],
      "availability": "available"
    },
    {
      "id": 10,
      "name": "Jackie Tran",
      "skills": ["C++", "Robotics", "Computer Vision"],
      "experience_years": 6,
      "projects": ["Autonomous Drone", "Factory Robot Controller"],
      "availability": "unavailable"
    },
    {
      "id": 11,
      "name": "Karan Kapoor",
      "skills": ["Python", "Pandas", "Scikit-learn"],
      "experience_years": 3,
      "projects": ["Sales Prediction Model", "Customer Segmentation"],
      "availability": "available"
    },
    {
      "id": 12,
      "name": "Lena Park",
      "skills": ["JavaScript", "TypeScript", "Next.js"],
      "experience_years": 4,
      "projects": ["Landing Pages", "SaaS Dashboard"],
      "availability": "available"
    },
    {
      "id": 13,
      "name": "Mohan Raj",
      "skills": ["Azure", "PowerShell", "CI/CD"],
      "experience_years": 5,
      "projects": ["Infrastructure-as-Code", "Log Analytics"],
      "availability": "unavailable"
    },
    {
      "id": 14,
      "name": "Nina D'Souza",
      "skills": ["Machine Learning", "Healthcare", "OpenCV"],
      "experience_years": 4,
      "projects": ["X-ray Scanner AI", "Health Risk Monitor"],
      "availability": "available"
    },
    {
      "id": 15,
      "name": "Om Prakash",
      "skills": ["React", "GraphQL", "Redux"],
      "experience_years": 3,
      "projects": ["Job Portal", "Chat App"],
      "availability": "available"
    },
    {
  "id": 16,
  "name": "Pooja Reddy",
  "skills": ["Python", "Flask", "PostgreSQL"],
  "experience_years": 4,
  "projects": ["Inventory Management System", "Bug Tracking Tool"],
  "availability": "available"
},
{
  "id": 17,
  "name": "Rajiv Bansal",
  "skills": ["Scala", "Apache Spark", "Kafka"],
  "experience_years": 6,
  "projects": ["Real-Time Fraud Detection", "Ad Recommendation Engine"],
  "availability": "unavailable"
},
{
  "id": 18,
  "name": "Sneha Kulkarni",
  "skills": ["Data Engineering", "Airflow", "BigQuery"],
  "experience_years": 5,
  "projects": ["ETL for Healthcare Analytics", "Data Lake Setup"],
  "availability": "available"
},
{
  "id": 19,
  "name": "Tarun Verma",
  "skills": ["Go", "Docker", "gRPC"],
  "experience_years": 4,
  "projects": ["Scalable Payment Gateway", "Container Orchestration"],
  "availability": "unavailable"
}

  ]
}


# Save to a file
with open("employees.json", "w") as f:
    json.dump(data, f, indent=2)

print("File saved as employees.json ✅")

"""**2. AI/ML Component (RAG System)**

Install Requirements
"""

import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer

# STEP 1: Load the embedding model (runs offline after first download)
print("🔁 Loading model...")
model = SentenceTransformer('all-MiniLM-L6-v2')

# STEP 2: Load your employee data
with open("employees.json") as f:
    employees = json.load(f)["employees"]

employee_texts = []
employee_ids = []

for emp in employees:
    summary = f"{emp['name']} with {emp['experience_years']} years experience. Skills: {', '.join(emp['skills'])}. Projects: {', '.join(emp['projects'])}. Availability: {emp['availability']}"
    employee_texts.append(summary)
    employee_ids.append(emp["id"])

# STEP 3: Create embeddings using sentence-transformers
print("📡 Generating embeddings locally...")
embeddings = model.encode(employee_texts)

# STEP 4: Store embeddings in FAISS
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings).astype('float32'))

# Save index and employee IDs for reuse
faiss.write_index(index, "employee_index.faiss")
with open("employee_ids.json", "w") as f:
    json.dump(employee_ids, f)

print("✅ FAISS index created and saved successfully!")

# STEP 5: Semantic search function
def search_employees(query, k=5):
    query_emb = model.encode([query])
    query_vector = np.array(query_emb).astype('float32')

    distances, indices = index.search(query_vector, k)
    results = []
    for idx in indices[0]:
        emp_id = employee_ids[idx]
        emp = next((e for e in employees if e["id"] == emp_id), None)
        if emp:
            results.append(emp)
    return results

# STEP 6: Run a sample query
def generate_natural_response(query, results):
    if not results:
        return f"❌ Sorry, no matches found for: '{query}'. You can try refining your query or using broader terms."

    intro = f"✅ Based on your request: \"{query}\", I found {len(results)} suitable candidate{'s' if len(results) > 1 else ''}:\n\n"
    body = ""

    for emp in results:
        name = emp['name']
        skills = ", ".join(emp['skills'])
        projects = ", ".join(emp['projects'])
        years = emp['experience_years']
        availability = emp['availability']

        profile = f"• **{name}** has {years} years of experience. Key skills include {skills}. They've worked on projects such as {projects}. Currently **{availability}**.\n"
        body += profile + "\n"

    closing = "Would you like more details or check availability for meetings?"
    return intro + body + closing

if __name__ == "__main__":
    user_query = "Looking for someone with machine learning experience in healthcare"
    print(f"\n🔍 Searching for: {user_query}\n")

    matches = search_employees(user_query)
    response = generate_natural_response(user_query, matches)

    print("\n🧠 AI Chatbot Response:\n")
    print(response)

def generate_natural_response(query, results):
    if not results:
        return f"❌ Sorry, no matches found for: '{query}'. You can try refining your query or using broader terms."

    intro = f"✅ Based on your request: \"{query}\", I found {len(results)} suitable candidate{'s' if len(results) > 1 else ''}:\n\n"
    body = ""

    for emp in results:
        name = emp['name']
        skills = ", ".join(emp['skills'])
        projects = ", ".join(emp['projects'])
        years = emp['experience_years']
        availability = emp['availability']

        profile = f"• **{name}** has {years} years of experience. Key skills include {skills}. They've worked on projects such as {projects}. Currently **{availability}**.\n"
        body += profile + "\n"

    closing = "Would you like more details or check availability for meetings?"
    return intro + body + closing

"""FAST API"""



from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import faiss
import json
import numpy as np
from sentence_transformers import SentenceTransformer

# Load model, FAISS index, and employee data
model = SentenceTransformer("all-MiniLM-L6-v2")
index = faiss.read_index("employee_index.faiss")

with open("employees.json") as f:
    employees = json.load(f)["employees"]

with open("employee_ids.json") as f:
    employee_ids = json.load(f)

# App init
app = FastAPI()

# Request model
class ChatQuery(BaseModel):
    query: str
    top_k: int = 5

# Search logic
def search_employees(query, k):
    query_emb = model.encode([query])
    query_vector = np.array(query_emb).astype('float32')
    distances, indices = index.search(query_vector, k)

    results = []
    for idx in indices[0]:
        emp_id = employee_ids[idx]
        emp = next((e for e in employees if e["id"] == emp_id), None)
        if emp:
            results.append(emp)
    return results

# Response generation
def generate_natural_response(query, results):
    if not results:
        return f"❌ Sorry, no matches found for: '{query}'. Try a broader search."

    intro = f"✅ Based on your query: \"{query}\", I found {len(results)} candidate{'s' if len(results) > 1 else ''}:\n\n"
    body = ""

    for emp in results:
        name = emp['name']
        skills = ", ".join(emp['skills'])
        projects = ", ".join(emp['projects'])
        years = emp['experience_years']
        availability = emp['availability']
        profile = f"• **{name}** has {years} years experience. Skills: {skills}. Projects: {projects}. Availability: {availability}.\n"
        body += profile + "\n"

    closing = "Would you like to explore their profiles or schedule a call?"
    return intro + body + closing

# Main chat endpoint
@app.post("/chat")
def chat(query: ChatQuery):
    try:
        matches = search_employees(query.query, query.top_k)
        response = generate_natural_response(query.query, matches)
        return {"response": response}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Optional raw endpoint
@app.get("/employees/search")
def get_employees(skill: str = "", min_exp: int = 0):
    filtered = [
        emp for emp in employees
        if skill.lower() in [s.lower() for s in emp["skills"]] and emp["experience_years"] >= min_exp
    ]
    return {"results": filtered}
